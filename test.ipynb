{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5410691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Preprocessing Output\n",
      "\n",
      "Original: Patient reports chest pain radiating to the left arm and jaw, suggestive of angina.\n",
      "- left arm\n",
      "\n",
      "Original: Diagnosed with type 2 diabetes mellitus and prescribed metformin 500mg twice daily.\n",
      "\n",
      "Original: Complains of blurred vision and frequent urination over the past few weeks.\n",
      "- blurred vision\n",
      "- frequent urination\n",
      "- past few weeks\n",
      "\n",
      "Original: MRI scan reveals degenerative disc disease at L4-L5 level with mild spinal stenosis.\n",
      "- degenerative disc disease\n",
      "- disc disease at ll level\n",
      "- mild spinal stenosis\n",
      "\n",
      "Original: Noted history of hypertension and hyperlipidemia for over 10 years.\n",
      "- history of hypertension\n",
      "- hyperlipidemia for over years\n",
      "\n",
      "Original: Recent lab tests show elevated liver enzymes and fatty infiltration of the liver.\n",
      "- fatty infiltration\n",
      "- recent lab tests\n",
      "\n",
      "Original: Experiencing abdominal bloating, nausea, and reduced appetite.\n",
      "- abdominal bloating\n",
      "- abdominal bloating nausea\n",
      "- bloating nausea\n",
      "\n",
      "Original: Underwent laparoscopic cholecystectomy last month due to gallstones.\n",
      "- last month\n",
      "- month due to gallstones\n",
      "\n",
      "Original: Echocardiogram shows reduced ejection fraction consistent with systolic heart failure.\n",
      "- systolic heart failure\n",
      "\n",
      "Original: The patient has mild cognitive impairment and difficulty with short-term memory.\n",
      "- mild cognitive impairment\n",
      "\n",
      "\n",
      "🔹 Matched Patterns\n",
      "\n",
      "left arm                       ['ADJ', 'NOUN']\n",
      "blurred vision                 ['ADJ', 'NOUN']\n",
      "frequent urination             ['ADJ', 'NOUN']\n",
      "past few weeks                 ['ADJ', 'NOUN']\n",
      "degenerative disc disease      ['ADJ', 'NOUN']\n",
      "mild spinal stenosis           ['ADJ', 'NOUN']\n",
      "disc disease at ll level       ['NOUN', 'ADP', 'NOUN']\n",
      "history of hypertension        ['NOUN', 'ADP', 'NOUN']\n",
      "hyperlipidemia for over years  ['NOUN', 'ADP', 'NOUN']\n",
      "recent lab tests               ['ADJ', 'NOUN']\n",
      "fatty infiltration             ['ADJ', 'NOUN']\n",
      "abdominal bloating             ['ADJ', 'NOUN']\n",
      "bloating nausea                ['NOUN', 'NOUN']\n",
      "abdominal bloating nausea      ['ADJ', 'NOUN', 'NOUN']\n",
      "last month                     ['ADJ', 'NOUN']\n",
      "month due to gallstones        ['NOUN', 'ADP', 'NOUN']\n",
      "systolic heart failure         ['NOUN', 'NOUN']\n",
      "mild cognitive impairment      ['ADJ', 'NOUN']\n",
      "\n",
      "🔹 Scoring (Unithood & Termhood)\n",
      "\n",
      "abdominal bloating             U: 3 | T: 3 | ✅\n",
      "abdominal bloating nausea      U: 3 | T: 3 | ✅\n",
      "bloating nausea                U: 3 | T: 3 | ✅\n",
      "blurred vision                 U: 3 | T: 3 | ✅\n",
      "degenerative disc disease      U: 3 | T: 3 | ✅\n",
      "disc disease at ll level       U: 3 | T: 3 | ✅\n",
      "fatty infiltration             U: 3 | T: 3 | ✅\n",
      "frequent urination             U: 3 | T: 3 | ✅\n",
      "history of hypertension        U: 3 | T: 2 | ✅\n",
      "hyperlipidemia for over years  U: 3 | T: 3 | ✅\n",
      "last month                     U: 3 | T: 3 | ✅\n",
      "left arm                       U: 3 | T: 3 | ✅\n",
      "mild cognitive impairment      U: 3 | T: 3 | ✅\n",
      "mild spinal stenosis           U: 3 | T: 3 | ✅\n",
      "month due to gallstones        U: 3 | T: 3 | ✅\n",
      "past few weeks                 U: 3 | T: 3 | ✅\n",
      "recent lab tests               U: 3 | T: 3 | ✅\n",
      "systolic heart failure         U: 3 | T: 3 | ✅\n",
      "\n",
      "✅ Final Extracted Terms\n",
      "['abdominal bloating', 'abdominal bloating nausea', 'bloating nausea', 'blurred vision', 'degenerative disc disease', 'disc disease at ll level', 'fatty infiltration', 'frequent urination', 'history of hypertension', 'hyperlipidemia for over years', 'last month', 'left arm', 'mild cognitive impairment', 'mild spinal stenosis', 'month due to gallstones', 'past few weeks', 'recent lab tests', 'systolic heart failure']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# ---------- Setup Transformer Model for POS Tagging ----------\n",
    "model_name = \"vblagoje/bert-english-uncased-finetuned-pos\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "pos_tagger = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# ---------- POS Patterns ----------\n",
    "POS_PATTERNS = [\n",
    "    ['ADJ', 'NOUN'],\n",
    "    ['NOUN', 'NOUN'],\n",
    "    ['ADJ', 'NOUN', 'NOUN'],\n",
    "    ['PROPN', 'NOUN'],\n",
    "    ['NOUN', 'ADP', 'NOUN']\n",
    "]\n",
    "\n",
    "# ---------- Preprocessing ----------\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# ---------- Clean WordPiece Fragments ----------\n",
    "def clean_wordpieces(tagged):\n",
    "    words = []\n",
    "    current_word = \"\"\n",
    "    for t in tagged:\n",
    "        w = t['word']\n",
    "        if w.startswith(\"##\"):\n",
    "            current_word += w[2:]\n",
    "        else:\n",
    "            if current_word:\n",
    "                words.append(current_word)\n",
    "            current_word = w\n",
    "    if current_word:\n",
    "        words.append(current_word)\n",
    "    return [w.lower() for w in words]\n",
    "\n",
    "# ---------- PoS Tagging ----------\n",
    "def get_lemmas_and_pos(text):\n",
    "    tagged = pos_tagger(text)\n",
    "    cleaned_words = clean_wordpieces(tagged)\n",
    "    pos_tags = [t['entity_group'] for t in tagged if not t['word'].startswith(\"##\")]\n",
    "    return cleaned_words, pos_tags\n",
    "\n",
    "# ---------- Pattern Matching ----------\n",
    "def match_patterns(words, pos_tags, patterns):\n",
    "    matched = []\n",
    "    for window in range(2, 5):\n",
    "        for i in range(len(words) - window + 1):\n",
    "            sub_words = words[i:i + window]\n",
    "            sub_tags = pos_tags[i:i + window]\n",
    "            if sub_tags in patterns:\n",
    "                matched.append((\" \".join(sub_words), sub_tags))\n",
    "    return matched\n",
    "\n",
    "# ---------- Unithood Score ----------\n",
    "def unithood_score(phrase, doc_freqs):\n",
    "    score = 0\n",
    "    if doc_freqs[phrase] >= 1: score += 1\n",
    "    if len(phrase.split()) > 1: score += 1\n",
    "    if re.search(r\"\\b[a-z]+\\s[a-z]+\", phrase): score += 1\n",
    "    return score\n",
    "\n",
    "# ---------- Termhood Score ----------\n",
    "def termhood_score(phrase):\n",
    "    score = 0\n",
    "    stop_words = {\"the\", \"and\", \"in\", \"of\", \"no\"}\n",
    "    tokens = phrase.split()\n",
    "    if len(tokens) > 1: score += 1\n",
    "    if not any(w in stop_words for w in tokens): score += 1\n",
    "    if any(char.isalpha() for char in phrase): score += 1\n",
    "    return score\n",
    "\n",
    "# ---------- Main Extraction Function ----------\n",
    "def extract_terms_verbose(emr_texts, threshold_u=2, threshold_t=2):\n",
    "    all_phrases = []\n",
    "    all_matches = []\n",
    "\n",
    "    print(\"\\n🔹 Preprocessing Output\\n\")\n",
    "    for text in emr_texts:\n",
    "        print(f\"Original: {text}\")\n",
    "        clean_text = preprocess(text)\n",
    "        words, pos_tags = get_lemmas_and_pos(clean_text)\n",
    "        phrases = match_patterns(words, pos_tags, POS_PATTERNS)\n",
    "        simplified = sorted(set([p[0] for p in phrases]))\n",
    "        all_phrases.extend(simplified)\n",
    "        all_matches.extend(phrases)\n",
    "        for s in simplified:\n",
    "            print(f\"- {s}\")\n",
    "        print()\n",
    "\n",
    "    doc_freqs = Counter(all_phrases)\n",
    "\n",
    "    print(\"\\n🔹 Matched Patterns\\n\")\n",
    "    for phrase, tags in all_matches:\n",
    "        print(f\"{phrase:<30} {tags}\")\n",
    "\n",
    "    print(\"\\n🔹 Scoring (Unithood & Termhood)\\n\")\n",
    "    results = []\n",
    "    for phrase in sorted(set(all_phrases)):\n",
    "        u_score = unithood_score(phrase, doc_freqs)\n",
    "        t_score = termhood_score(phrase)\n",
    "        accepted = u_score >= threshold_u and t_score >= threshold_t\n",
    "        results.append((phrase, u_score, t_score, accepted))\n",
    "        print(f\"{phrase:<30} U: {u_score} | T: {t_score} | {'✅' if accepted else '❌'}\")\n",
    "\n",
    "    final_terms = [r[0] for r in results if r[3]]\n",
    "\n",
    "    print(\"\\n✅ Final Extracted Terms\")\n",
    "    print(final_terms)\n",
    "    return final_terms\n",
    "\n",
    "# ---------- Example Usage ----------\n",
    "if __name__ == \"__main__\":\n",
    "    EMR_Texts = [\n",
    "    \"Patient reports chest pain radiating to the left arm and jaw, suggestive of angina.\",\n",
    "    \"Diagnosed with type 2 diabetes mellitus and prescribed metformin 500mg twice daily.\",\n",
    "    \"Complains of blurred vision and frequent urination over the past few weeks.\",\n",
    "    \"MRI scan reveals degenerative disc disease at L4-L5 level with mild spinal stenosis.\",\n",
    "    \"Noted history of hypertension and hyperlipidemia for over 10 years.\",\n",
    "    \"Recent lab tests show elevated liver enzymes and fatty infiltration of the liver.\",\n",
    "    \"Experiencing abdominal bloating, nausea, and reduced appetite.\",\n",
    "    \"Underwent laparoscopic cholecystectomy last month due to gallstones.\",\n",
    "    \"Echocardiogram shows reduced ejection fraction consistent with systolic heart failure.\",\n",
    "    \"The patient has mild cognitive impairment and difficulty with short-term memory.\"\n",
    "]\n",
    "\n",
    "\n",
    "    extract_terms_verbose(EMR_Texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "def evaluate_extraction(emr_texts, ground_truth):\n",
    "    start_time = time.time()\n",
    "    predicted_terms = extract_terms_verbose(emr_texts)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Flatten all terms\n",
    "    pred_set = set(predicted_terms)\n",
    "    true_set = set([item for sublist in ground_truth for item in sublist])\n",
    "\n",
    "    tp = len(pred_set & true_set)\n",
    "    fp = len(pred_set - true_set)\n",
    "    fn = len(true_set - pred_set)\n",
    "    tn = 0  # Hard to define in open vocabulary tasks\n",
    "\n",
    "    # Avoid division by zero\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "    accuracy = tp / len(true_set) if true_set else 0\n",
    "\n",
    "    print(\"\\n📊 Quantitative Evaluation\")\n",
    "    print(f\"Precision    : {precision:.2f}\")\n",
    "    print(f\"Recall       : {recall:.2f}\")\n",
    "    print(f\"F1 Score     : {f1:.2f}\")\n",
    "    print(f\"Accuracy     : {accuracy:.2f}\")\n",
    "    print(f\"Exec Time    : {end_time - start_time:.2f} sec\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
